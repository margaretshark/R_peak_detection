{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dfedb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c93319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af42e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from collections import Counter \n",
    "from scipy import signal as sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01af1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from wfdb import processing\n",
    "import os\n",
    "from functools import partial\n",
    "from utils import plot_signal_with_r_peaks, load_patient, extract_test_windows, mean\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1396862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_unet1d import *\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ef939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'mit-bih-arrhythmia'\n",
    "\n",
    "data_dir = 'filtered-mit-bih-arrhythmia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b07bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size is 7200\n"
     ]
    }
   ],
   "source": [
    "# Window/Segment length \n",
    "\n",
    "l = 20 #seconds\n",
    "# window stride for testing. \n",
    "\n",
    "s = 10 #seconds\n",
    "# Sapmling frequency of ecg signal is 360 hz. \n",
    "# (https://archive.physionet.org/physiobank/database/html/mitdbdir/intro.htm#annotations)\n",
    "\n",
    "fs = 360\n",
    "# Window/Segment length in samples. \n",
    "win_size = l*fs\n",
    "print(f\"Window size is {win_size}\")\n",
    "# Stride for test window in samples. \n",
    "stride = s*fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99b9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ecg):\n",
    "    \n",
    "    signal = ecg.flatten()\n",
    "\n",
    "    # Apply DWT\n",
    "    wavelet = 'db4'\n",
    "    level = 9\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "\n",
    "    # Remove baseline wandering\n",
    "    coeffs[1:] = [pywt.threshold(i, np.std(i)/2) for i in coeffs[1:]]\n",
    "    filtered_signal = pywt.waverec(coeffs, wavelet)\n",
    "\n",
    "    # Apply lowpass filter\n",
    "    nyquist = int(180)\n",
    "    cutoff = 40\n",
    "    b, a = sig.butter(4, cutoff/nyquist, 'low')\n",
    "    filtered_signal = sig.filtfilt(b, a, filtered_signal)\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6212de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_training_windows(ecg, win_size, Rpeaks_pos):\n",
    "    \n",
    "    print('Preparing Training Data for R-peaks detection')\n",
    "\n",
    "    # Total windows in ecg. (Number of training examples)\n",
    "    tot_wins = int(len(ecg)/win_size)\n",
    "\n",
    "    X_train = np.zeros((tot_wins,win_size), dtype=np.float64)\n",
    "    y_train = np.zeros((tot_wins,win_size))\n",
    "\n",
    "    # Annotations for each window\n",
    "    R = []\n",
    "    \n",
    "    normalize = partial(processing.normalize_bound, lb=-1, ub=1)\n",
    "    \n",
    "    for i in tqdm(range(tot_wins)):\n",
    "    \n",
    "        # Start of window in whole ecg stream\n",
    "        st = i*win_size\n",
    "        \n",
    "        # End of window\n",
    "        end = st + win_size\n",
    "\n",
    "        # R peaks in the current window\n",
    "        rIndx = np.where((Rpeaks_pos >= st) & (Rpeaks_pos < end))[0]\n",
    "\n",
    "        R.append(Rpeaks_pos[rIndx]-st)\n",
    "\n",
    "                  \n",
    "        for j in Rpeaks_pos[rIndx]:\n",
    "            r = int(j)-st\n",
    "            y_train[i,r-2:r+3] = 1\n",
    "\n",
    "\n",
    "        # If ecg window is non zero. Normalize it. \n",
    "        if ecg[st:end].any():\n",
    "            X_train[i,:] = np.squeeze(np.apply_along_axis(normalize, 0, ecg[st:end]))\n",
    "        # All zero ecg window\n",
    "        else:\n",
    "            X_train[i,:] = ecg[st:end].T\n",
    "\n",
    "\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    \n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    \n",
    "    return X_train, y_train, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c8a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of patient records is 48 \n"
     ]
    }
   ],
   "source": [
    "patients = [x for x in list(set([x.split('.')[0] for x in os.listdir(f'./{data_dir}/')])) if len(x) > 1]\n",
    "print(f\"The number of patient records is {len(patients)} \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28879b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['231', '115', '215', '208', '219', '202', '233', '105', '220',\n",
       "       '222', '102', '121', '221', '210', '205', '119', '212', '230',\n",
       "       '109', '203', '100', '101', '116', '200', '122', '207', '113',\n",
       "       '214', '104', '228', '213', '232', '117', '112', '217', '103',\n",
       "       '111', '123', '118', '124', '201', '106', '234', '107', '209',\n",
       "       '223', '114', '108'], dtype='<U3')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState(seed=42).permutation(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04143ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define  the splitting strategy for training our detection model\n",
    "def data_split(patients):\n",
    "    SEED = 42\n",
    "    indices = np.random.RandomState(seed=SEED).permutation(patients)\n",
    "    m = len(patients)\n",
    "    training_idx, val_idx, test_idx = indices[:int(m*0.7)], indices[int(m*0.7):int(m*0.85)], indices[int(m*0.85):]\n",
    "\n",
    "    return training_idx, test_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d2ec836",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idx, test_idx, val_idx = data_split(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db942f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_testing_windows(ecg, win_size, Rpeaks_pos):\n",
    "    overlap = 2000\n",
    "    hop_size = win_size - overlap\n",
    "    \n",
    "    ecg_pad = np.pad(ecg,(0, 5200), mode='edge')\n",
    "    \n",
    "    print('Preparing testing data for R-peaks detection')\n",
    "    \n",
    "    # Total windows in ecg. (Number of training examples)\n",
    "    tot_wins = int((len(ecg) - overlap)/ hop_size)\n",
    "    \n",
    "    X_train = np.zeros((tot_wins,win_size), dtype=np.float64)\n",
    "    y_train = np.zeros((tot_wins,win_size))\n",
    "\n",
    "    # Annotations for each window\n",
    "    R = []\n",
    "    \n",
    "    normalize = partial(processing.normalize_bound, lb=-1, ub=1)\n",
    "    \n",
    "#     for i in range(0, len(pad_sig), stride):\n",
    "#     for i in range(0, len(tot_wins), stride):\n",
    "\n",
    "    pad_id = np.arange(ecg_pad.shape[0])\n",
    "    \n",
    "    for i in tqdm(range(tot_wins)):\n",
    "    \n",
    "        # Start of window in whole ecg stream\n",
    "        st = i*win_size\n",
    "        \n",
    "        # End of window\n",
    "        end = st + win_size\n",
    "\n",
    "        # R peaks in the current window\n",
    "        rIndx = np.where((Rpeaks_pos >= st) & (Rpeaks_pos < end))[0]\n",
    "\n",
    "        R.append(Rpeaks_pos[rIndx]-st)\n",
    "\n",
    "                  \n",
    "        for j in Rpeaks_pos[rIndx]:\n",
    "            r = int(j)-st\n",
    "            y_train[i,r-2:r+3] = 1\n",
    "\n",
    "\n",
    "        # If ecg window is non zero. Normalize it. \n",
    "        if ecg_pad[st:end].any():\n",
    "            X_train[i,:] = np.squeeze(np.apply_along_axis(normalize, 0, ecg_pad[st:end]))\n",
    "        # All zero ecg window\n",
    "        else:\n",
    "#             print(i)\n",
    "            pass\n",
    "#             X_train[i,:] = ecg_pad[st:end].T\n",
    "\n",
    "\n",
    "    X_train = np.expand_dims(X_train, axis=1)\n",
    "    \n",
    "    y_train = np.expand_dims(y_train, axis=1)\n",
    "    \n",
    "    return X_train, y_train, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "878ec0f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_laoding(idx, win_size, data_dir): \n",
    "    \n",
    "    for i, pat_num in zip(range(len(idx)), idx):\n",
    "\n",
    "        ecg, Rpeaks_pos = load_patient(data_dir, str(pat_num))\n",
    "\n",
    "        X_train_s, y_train_s, R = extract_training_windows(ecg, win_size, Rpeaks_pos)\n",
    "        if i == 0:\n",
    "            X_train = X_train_s\n",
    "            y_train = y_train_s\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X_train_s))\n",
    "            y_train = np.concatenate((y_train, y_train_s))\n",
    "            \n",
    "    return X_train , y_train, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58cd1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_laoding_testing(idx, win_size, data_dir): \n",
    "    \n",
    "#     for i, pat_num in zip(range(len(idx)), idx):\n",
    "\n",
    "#         ecg, Rpeaks_pos = load_patient(data_dir, str(pat_num))\n",
    "        \n",
    "#         X_test_s, y_test_s, R = extract_testing_windows(ecg, win_size, Rpeaks_pos)\n",
    "#         if i == 0:\n",
    "#             X_test = X_test_s\n",
    "#             y_test = y_test_s\n",
    "#         else:\n",
    "#             X_test = np.concatenate((X_test, X_test_s))\n",
    "#             y_test = np.concatenate((y_test, y_test_s))\n",
    "            \n",
    "#     return X_test , X_test, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcff60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d6cc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir = 'mit-bih-arrhythmia',\n",
    "                 idx_im = training_idx, label = 'train'):\n",
    "        \n",
    "        self.win_size = 7200\n",
    "        self.idx_im = idx_im\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        if label == 'train':\n",
    "            self.X, self.y, self.R = data_laoding(self.idx_im, self.win_size, self.data_dir)\n",
    "            \n",
    "        if label == 'test':\n",
    "            self.X, self.y, self.R = data_laoding_testing(self.idx_im, self.win_size, self.data_dir)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.idx_im)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X_inp = torch.from_numpy(self.X[idx]).float()\n",
    "        y_inp = torch.from_numpy(self.y[idx]).float()\n",
    "        half_pad = (7232 - self.win_size) // 2\n",
    "        p = torch.nn.ConstantPad1d(half_pad, 0)\n",
    "        X_inp1 = p(X_inp)\n",
    "        y_inp1 = p(y_inp)\n",
    "\n",
    "        return X_inp1, y_inp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4516cce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 231\n",
      "Total Beats :  328\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 10469.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 115\n",
      "Total Beats :  1954\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 13623.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 215\n",
      "Total Beats :  3367\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 12522.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  2631\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 13794.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 219\n",
      "Total Beats :  2174\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 15695.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 202\n",
      "Total Beats :  2124\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 14985.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 233\n",
      "Total Beats :  3139\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 11534.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  2568\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 11141.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 220\n",
      "Total Beats :  2065\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 13156.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 222\n",
      "Total Beats :  2406\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 15106.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 102\n",
      "Total Beats :  108\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 18453.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 121\n",
      "Total Beats :  1864\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16134.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 221\n",
      "Total Beats :  2450\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 14012.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 210\n",
      "Total Beats :  2634\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 10978.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  2658\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 15318.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  2090\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 17110.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  924\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 15552.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  2463\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 13228.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  39\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16793.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  3018\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 12966.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 100\n",
      "Total Beats :  2274\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 13505.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 101\n",
      "Total Beats :  1864\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 13865.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 116\n",
      "Total Beats :  2413\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 15805.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 200\n",
      "Total Beats :  2747\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 14677.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 122\n",
      "Total Beats :  2477\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 14780.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 207\n",
      "Total Beats :  236\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16589.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 113\n",
      "Total Beats :  1790\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 17387.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 214\n",
      "Total Beats :  281\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 18348.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 104\n",
      "Total Beats :  210\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 17917.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 228\n",
      "Total Beats :  2094\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16929.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 213\n",
      "Total Beats :  2929\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 15105.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 232\n",
      "Total Beats :  1383\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16697.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 117\n",
      "Total Beats :  1536\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16074.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 112\n",
      "Total Beats :  2540\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16781.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  473\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 17821.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  2085\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16123.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 111\n",
      "Total Beats :  2\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 20505.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 123\n",
      "Total Beats :  1519\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 16203.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 118\n",
      "Total Beats :  113\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 17311.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Beats :  62\n",
      "Preparing Training Data for R-peaks detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 20505.59it/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = CustomImageDataset('filtered-mit-bih-arrhythmia', training_idx, 'train') \n",
    "train_dataloader = DataLoader(training_data, batch_size=4, shuffle=True)\n",
    "\n",
    "val_data = CustomImageDataset('filtered-mit-bih-arrhythmia',  val_idx, 'train')\n",
    "val_dataloader = DataLoader(val_data, batch_size=4, shuffle=True)\n",
    "\n",
    "# testing_data = CustomImageDataset('filtered-mit-bih-arrhythmia',  test_idx, 'test')\n",
    "# test_dataloader = DataLoader(testing_data, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c37999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Total Windows : ', len(X_train))\n",
    "\n",
    "\n",
    "# # All indexes of training windows.\n",
    "# idx = np.arange(len(X_train))\n",
    "\n",
    "# # indexes other than S and V beats. (Normal R peaks)\n",
    "# rem_idx =  idx\n",
    "\n",
    "# # # Choose 50% of remaining. \n",
    "# norm_idx = np.random.choice(rem_idx, size=int(len(rem_idx)*(1/3)), replace=False)\n",
    "\n",
    "# X_train = np.concatenate((X_train[norm_idx],X_train[idx]))\n",
    "# y_train = np.concatenate((y_train[norm_idx],y_train[idx]))\n",
    "\n",
    "# assert len(X_train) == len(y_train)\n",
    "\n",
    "# print('Selected Windows : ', len(X_train))\n",
    "\n",
    "# print('Saving Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd3c50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def setup_experiment(title, logdir=\"./logs\"):\n",
    "    experiment_name = \"{}@{}\".format(title, datetime.datetime.now().strftime(\"%d.%m.%Y-%H:%M:%S\"))\n",
    "    writer = SummaryWriter(log_dir=os.path.join(logdir, experiment_name))\n",
    "    best_model_path = f\"{title}.best.pth\"\n",
    "    return writer, experiment_name, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1dbfa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: UNet_1D@28.04.2023-15:43:33\n",
      "Model has 79,153 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = UNet_1D()\n",
    "\n",
    "\n",
    "# The learning rate needs to be lower than the default used by Adam, otherwise the learning can be unstable.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [20,40,60], gamma=0.5)\n",
    "\n",
    "writer, experiment_name, best_model_path = setup_experiment(model.__class__.__name__, logdir=\"./tb_transf\")\n",
    "print(f\"Experiment name: {experiment_name}\")\n",
    "\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters\")\n",
    "# sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18af0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, iterator, optimizer, criterion, phase='train', epoch=0, writer=None):\n",
    "    is_train = (phase == 'train')\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "\n",
    "    # variables for calculating accuracy\n",
    "    n_predicted = 0\n",
    "    n_true_predicted = 0\n",
    "    \n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for i, batch in enumerate(iterator):\n",
    "            global_i = len(iterator) * epoch + i\n",
    "            \n",
    "            # unpack batch\n",
    "            inputs, labels = batch\n",
    "#             text, postag = batch.text, batch.postag\n",
    "            \n",
    "            # make prediction\n",
    "            pred = model(inputs)\n",
    "            \n",
    "            \n",
    "            # calculate loss\n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            if is_train:\n",
    "                # make optimization step\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    " \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # dump epoch metrics to tensorboard\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(f\"loss_epoch/{phase}\", epoch_loss / len(iterator), epoch)\n",
    "\n",
    "        return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46c224e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.791\n",
      "\t Val. Loss: 0.511 \n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.608\n",
      "\t Val. Loss: 0.487 \n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.502\n",
      "\t Val. Loss: 0.456 \n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.426\n",
      "\t Val. Loss: 0.421 \n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.360\n",
      "\t Val. Loss: 0.377 \n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.310\n",
      "\t Val. Loss: 0.340 \n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.266\n",
      "\t Val. Loss: 0.311 \n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.229\n",
      "\t Val. Loss: 0.278 \n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.197\n",
      "\t Val. Loss: 0.241 \n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.169\n",
      "\t Val. Loss: 0.212 \n",
      "Epoch: 11\n",
      "\tTrain Loss: 0.140\n",
      "\t Val. Loss: 0.181 \n",
      "Epoch: 12\n",
      "\tTrain Loss: 0.127\n",
      "\t Val. Loss: 0.161 \n",
      "Epoch: 13\n",
      "\tTrain Loss: 0.106\n",
      "\t Val. Loss: 0.140 \n",
      "Epoch: 14\n",
      "\tTrain Loss: 0.099\n",
      "\t Val. Loss: 0.132 \n",
      "Epoch: 15\n",
      "\tTrain Loss: 0.086\n",
      "\t Val. Loss: 0.121 \n",
      "Epoch: 16\n",
      "\tTrain Loss: 0.078\n",
      "\t Val. Loss: 0.113 \n",
      "Epoch: 17\n",
      "\tTrain Loss: 0.067\n",
      "\t Val. Loss: 0.107 \n",
      "Epoch: 18\n",
      "\tTrain Loss: 0.061\n",
      "\t Val. Loss: 0.100 \n",
      "Epoch: 19\n",
      "\tTrain Loss: 0.052\n",
      "\t Val. Loss: 0.092 \n",
      "Epoch: 20\n",
      "\tTrain Loss: 0.047\n",
      "\t Val. Loss: 0.085 \n",
      "Epoch: 21\n",
      "\tTrain Loss: 0.044\n",
      "\t Val. Loss: 0.083 \n",
      "Epoch: 22\n",
      "\tTrain Loss: 0.040\n",
      "\t Val. Loss: 0.084 \n",
      "Epoch: 23\n",
      "\tTrain Loss: 0.035\n",
      "\t Val. Loss: 0.078 \n",
      "Epoch: 24\n",
      "\tTrain Loss: 0.032\n",
      "\t Val. Loss: 0.070 \n",
      "Epoch: 25\n",
      "\tTrain Loss: 0.031\n",
      "\t Val. Loss: 0.073 \n",
      "Epoch: 26\n",
      "\tTrain Loss: 0.029\n",
      "\t Val. Loss: 0.073 \n",
      "Epoch: 27\n",
      "\tTrain Loss: 0.026\n",
      "\t Val. Loss: 0.072 \n",
      "Epoch: 28\n",
      "\tTrain Loss: 0.024\n",
      "\t Val. Loss: 0.069 \n",
      "Epoch: 29\n",
      "\tTrain Loss: 0.022\n",
      "\t Val. Loss: 0.067 \n",
      "Epoch: 30\n",
      "\tTrain Loss: 0.020\n",
      "\t Val. Loss: 0.066 \n",
      "Epoch: 31\n",
      "\tTrain Loss: 0.019\n",
      "\t Val. Loss: 0.057 \n",
      "Epoch: 32\n",
      "\tTrain Loss: 0.017\n",
      "\t Val. Loss: 0.068 \n",
      "Epoch: 33\n",
      "\tTrain Loss: 0.016\n",
      "\t Val. Loss: 0.058 \n",
      "Epoch: 34\n",
      "\tTrain Loss: 0.016\n",
      "\t Val. Loss: 0.066 \n",
      "Epoch: 35\n",
      "\tTrain Loss: 0.014\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 36\n",
      "\tTrain Loss: 0.013\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 37\n",
      "\tTrain Loss: 0.013\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 38\n",
      "\tTrain Loss: 0.012\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 39\n",
      "\tTrain Loss: 0.011\n",
      "\t Val. Loss: 0.057 \n",
      "Epoch: 40\n",
      "\tTrain Loss: 0.011\n",
      "\t Val. Loss: 0.061 \n",
      "Epoch: 41\n",
      "\tTrain Loss: 0.010\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 42\n",
      "\tTrain Loss: 0.010\n",
      "\t Val. Loss: 0.061 \n",
      "Epoch: 43\n",
      "\tTrain Loss: 0.009\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 44\n",
      "\tTrain Loss: 0.009\n",
      "\t Val. Loss: 0.062 \n",
      "Epoch: 45\n",
      "\tTrain Loss: 0.008\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 46\n",
      "\tTrain Loss: 0.008\n",
      "\t Val. Loss: 0.057 \n",
      "Epoch: 47\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.062 \n",
      "Epoch: 48\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.052 \n",
      "Epoch: 49\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 50\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 51\n",
      "\tTrain Loss: 0.007\n",
      "\t Val. Loss: 0.065 \n",
      "Epoch: 52\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.062 \n",
      "Epoch: 53\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.061 \n",
      "Epoch: 54\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 55\n",
      "\tTrain Loss: 0.006\n",
      "\t Val. Loss: 0.053 \n",
      "Epoch: 56\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.063 \n",
      "Epoch: 57\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.062 \n",
      "Epoch: 58\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.058 \n",
      "Epoch: 59\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.062 \n",
      "Epoch: 60\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.058 \n",
      "Epoch: 61\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.066 \n",
      "Epoch: 62\n",
      "\tTrain Loss: 0.005\n",
      "\t Val. Loss: 0.059 \n",
      "Epoch: 63\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 64\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.059 \n",
      "Epoch: 65\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.066 \n",
      "Epoch: 66\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.066 \n",
      "Epoch: 67\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.057 \n",
      "Epoch: 68\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.065 \n",
      "Epoch: 69\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.059 \n",
      "Epoch: 70\n",
      "\tTrain Loss: 0.004\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 71\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 72\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.060 \n",
      "Epoch: 73\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 74\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 75\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.065 \n",
      "Epoch: 76\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 77\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.063 \n",
      "Epoch: 78\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.068 \n",
      "Epoch: 79\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.066 \n",
      "Epoch: 80\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.066 \n",
      "Epoch: 81\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.061 \n",
      "Epoch: 82\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.068 \n",
      "Epoch: 83\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.064 \n",
      "Epoch: 84\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.069 \n",
      "Epoch: 85\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.067 \n",
      "Epoch: 86\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.070 \n",
      "Epoch: 87\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.070 \n",
      "Epoch: 88\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.070 \n",
      "Epoch: 89\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.072 \n",
      "Epoch: 90\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.070 \n",
      "Epoch: 91\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.068 \n",
      "Epoch: 92\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.069 \n",
      "Epoch: 93\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.073 \n",
      "Epoch: 94\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.068 \n",
      "Epoch: 95\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.072 \n",
      "Epoch: 96\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.070 \n",
      "Epoch: 97\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.083 \n",
      "Epoch: 98\n",
      "\tTrain Loss: 0.003\n",
      "\t Val. Loss: 0.071 \n",
      "Epoch: 99\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.071 \n",
      "Epoch: 100\n",
      "\tTrain Loss: 0.002\n",
      "\t Val. Loss: 0.069 \n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "log = 'logs'\n",
    "if not os.path.exists(log):\n",
    "    os.makedirs(log)\n",
    "best_model_path = f\"{log}/1d_unet.best.pth\"\n",
    "    \n",
    "best_val_loss = float('+inf')\n",
    "for epoch in range(n_epochs):    \n",
    "    train_loss = run_epoch(model, train_dataloader, optimizer, criterion, phase='train', epoch=epoch, writer = writer)\n",
    "    val_loss = run_epoch(model, val_dataloader, None, criterion, phase='val', epoch=epoch, writer=writer)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75b953d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(r_ref, r_ans, thr , fs):\n",
    "\n",
    "\n",
    "    FP = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    for j in range(len(r_ref)):\n",
    "        loc = np.where(np.abs(r_ans - r_ref[j]) <= thr*fs)[0]\n",
    "            \n",
    "        if len(loc) >= 1:\n",
    "            TP += 1\n",
    "            FP += len(loc) - 1\n",
    "        elif len(loc) == 0:\n",
    "            FN += 1\n",
    "\n",
    "    Recall = (TP / (FN + TP))*100\n",
    "    Precision = (TP / (FP + TP))*100\n",
    "\n",
    "    if Recall + Precision == 0:\n",
    "        F1_score = 0\n",
    "    else:\n",
    "        F1_score = (2 * Recall * Precision / (Recall + Precision))\n",
    "    print(\"Recall:{}, Precision(FNR):{}, F1-Score:{}\".format(Recall,Precision,F1_score))\n",
    "    print(\"Total {}\".format(len(r_ref)))\n",
    "    return TP, FN, FP, Precision, Recall, F1_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c9ef94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['TENSORBOARD_BINARY'] = './tb_trans'\n",
    "\n",
    "# %reload_ext tensorboard\n",
    "# logs_base_dir = \"./tb_trans\"\n",
    "# %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "438f9b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Patient : 201\n",
      "Total Beats :  1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 55363/55363 [00:03<00:00, 14265.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):37.1946414499606, F1-Score:54.221711659965536\n",
      "Total 1888\n",
      "Loading Data for Patient : 106\n",
      "Total Beats :  2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 62413/62413 [00:04<00:00, 14520.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):34.283819628647215, F1-Score:51.06172839506173\n",
      "Total 2068\n",
      "Loading Data for Patient : 234\n",
      "Total Beats :  2706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 67492/67492 [00:04<00:00, 13710.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):32.736511008952334, F1-Score:49.32555596062705\n",
      "Total 2706\n",
      "Loading Data for Patient : 107\n",
      "Total Beats :  60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 60329/60329 [00:04<00:00, 14652.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):28.846153846153843, F1-Score:44.776119402985074\n",
      "Total 60\n",
      "Loading Data for Patient : 209\n",
      "Total Beats :  3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 58969/58969 [00:03<00:00, 15139.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):32.394818541912, F1-Score:48.93668634268618\n",
      "Total 3026\n",
      "Loading Data for Patient : 223\n",
      "Total Beats :  2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 67085/67085 [00:04<00:00, 13974.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):34.39978847170809, F1-Score:51.19024198308086\n",
      "Total 2602\n",
      "Loading Data for Patient : 114\n",
      "Total Beats :  1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 56009/56009 [00:03<00:00, 14903.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):28.67186305975852, F1-Score:44.56586292908896\n",
      "Total 1876\n",
      "Loading Data for Patient : 108\n",
      "Total Beats :  1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 52882/52882 [00:03<00:00, 15066.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:100.0, Precision(FNR):36.91050094319849, F1-Score:53.9191671769749\n",
      "Total 1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# custom evaluation \n",
    "stats_R = []\n",
    "\n",
    "win_size = 7200\n",
    "stride = 7200//2\n",
    "model_path =  f\"{log}/1d_unet.best.pth\"\n",
    "\n",
    "model = UNet_1D()\n",
    "\n",
    "torch.load(model_path)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "tp_all = []\n",
    "fn_all = []\n",
    "fp_all = []\n",
    "for i, pat_num in zip(range(len(test_idx)), test_idx):\n",
    "    \n",
    "    ecg, Rpeaks_pos = load_patient(data_dir, str(pat_num))\n",
    "\n",
    "    padded_indices, data_windows = extract_test_windows(ecg, win_size, stride)\n",
    "    data_windows = np.transpose(data_windows, (0, 2, 1))\n",
    "\n",
    "    X_inp = torch.from_numpy(data_windows).float()\n",
    "    \n",
    "    half_pad = (7232 - 20*360) // 2\n",
    "    p = torch.nn.ConstantPad1d(half_pad, 0)\n",
    "    data_windows = p(X_inp)\n",
    "\n",
    "    predictions = model(data_windows)[:, :, 16:-16].detach().numpy()\n",
    "    predictions = np.transpose(predictions, (0, 2, 1))\n",
    "    \n",
    "    predictions = mean(win_idx=padded_indices, preds=predictions, \n",
    "                           orig_len=ecg.shape[0],win_size=win_size,\n",
    "                           stride= stride)\n",
    "    assert(predictions.shape == ecg.shape)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    above_thresh = predictions[predictions > threshold]\n",
    "    above_threshold_idx = np.where(predictions > threshold)[0]\n",
    "    \n",
    "    correct_up = processing.correct_peaks(sig=ecg,\n",
    "                                          peak_inds=above_threshold_idx,\n",
    "                                          search_radius=30,\n",
    "                                          smooth_window_size=30,\n",
    "                                          peak_dir='up')\n",
    "    \n",
    "    filtered_peaks = []\n",
    "    filtered_probs = []\n",
    "\n",
    "    for peak_id in tqdm(np.unique(correct_up)):\n",
    "\n",
    "        points_in_peak = np.where(correct_up == peak_id)[0]\n",
    "        if points_in_peak.shape[0] >= 5:\n",
    "            filtered_probs.append(above_thresh[points_in_peak].mean())\n",
    "            filtered_peaks.append(peak_id)\n",
    "    \n",
    "\n",
    "    filtered_peaks = np.asarray(filtered_peaks)\n",
    "    filtered_probs = np.asarray(filtered_probs)\n",
    "    \n",
    "    thr = 0.15 # 150 ms\n",
    "    fs = 360\n",
    "    TP, FN, FP, pr_pat, rec_pat, f1_pat = calculate_stats(Rpeaks_pos, filtered_peaks, thr, fs)\n",
    "    tp_all.append(TP)\n",
    "    fn_all.append(FN)\n",
    "    fp_all.append(FP)\n",
    "    \n",
    "    precision.append(pr_pat)\n",
    "    recall.append(rec_pat)\n",
    "    f1_score.append(f1_pat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d011c019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182, 1, 7232])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(X_inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13daa6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.179762118786385, 100.0, 49.74963423130878)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precision), np.mean(recall), np.mean(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4849e65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.21190402002332, 99.95071201730943, 58.30041044428638)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered data \n",
    "np.mean(precision), np.mean(recall), np.mean(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d480e1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d56112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3d60e6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.02923894402076, 99.52015426207396, 54.856202381625394)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered data \n",
    "np.mean(precision), np.mean(recall), np.mean(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f01f554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9e2450f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 16, 3616]             160\n",
      "        Downsample-2             [-1, 16, 3616]               0\n",
      "            Conv1d-3             [-1, 16, 1808]           2,320\n",
      "       BatchNorm1d-4             [-1, 16, 1808]              32\n",
      "        Downsample-5             [-1, 16, 1808]               0\n",
      "            Conv1d-6              [-1, 32, 904]           3,104\n",
      "       BatchNorm1d-7              [-1, 32, 904]              64\n",
      "        Downsample-8              [-1, 32, 904]               0\n",
      "            Conv1d-9              [-1, 32, 452]           6,176\n",
      "      BatchNorm1d-10              [-1, 32, 452]              64\n",
      "       Downsample-11              [-1, 32, 452]               0\n",
      "           Conv1d-12              [-1, 64, 226]           6,208\n",
      "      BatchNorm1d-13              [-1, 64, 226]             128\n",
      "       Downsample-14              [-1, 64, 226]               0\n",
      "           Conv1d-15              [-1, 64, 113]          12,352\n",
      "      BatchNorm1d-16              [-1, 64, 113]             128\n",
      "       Downsample-17              [-1, 64, 113]               0\n",
      "  ConvTranspose1d-18              [-1, 64, 226]          12,352\n",
      "      BatchNorm1d-19              [-1, 64, 226]             128\n",
      "         Upsample-20              [-1, 64, 226]               0\n",
      "  ConvTranspose1d-21              [-1, 32, 452]          12,320\n",
      "      BatchNorm1d-22              [-1, 32, 452]              64\n",
      "         Upsample-23              [-1, 32, 452]               0\n",
      "  ConvTranspose1d-24              [-1, 32, 904]          12,320\n",
      "      BatchNorm1d-25              [-1, 32, 904]              64\n",
      "         Upsample-26              [-1, 32, 904]               0\n",
      "  ConvTranspose1d-27             [-1, 16, 1808]           6,160\n",
      "      BatchNorm1d-28             [-1, 16, 1808]              32\n",
      "         Upsample-29             [-1, 16, 1808]               0\n",
      "  ConvTranspose1d-30             [-1, 16, 3616]           4,624\n",
      "      BatchNorm1d-31             [-1, 16, 3616]              32\n",
      "         Upsample-32             [-1, 16, 3616]               0\n",
      "  ConvTranspose1d-33              [-1, 1, 7232]             289\n",
      "          Sigmoid-34              [-1, 1, 7232]               0\n",
      "  Conv1DTranspose-35              [-1, 1, 7232]               0\n",
      "================================================================\n",
      "Total params: 79,121\n",
      "Trainable params: 79,121\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 6.51\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 6.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(model(20*360))\n",
    "\n",
    "summary(model, (1, 7232))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d677421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "101\n",
      "208\n",
      "220\n",
      "115\n",
      "219\n",
      "116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, pat_num in zip(range(len(test_idx)), test_idx):\n",
    "    print(pat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1082359f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet_1D(\n",
       "  (down_stack): ModuleList(\n",
       "    (0): Downsample(\n",
       "      (conv): Conv1d(1, 16, kernel_size=(9,), stride=(2,), padding=(4,))\n",
       "      (batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Downsample(\n",
       "      (conv): Conv1d(16, 16, kernel_size=(9,), stride=(2,), padding=(4,))\n",
       "      (batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Downsample(\n",
       "      (conv): Conv1d(16, 32, kernel_size=(6,), stride=(2,), padding=(2,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Downsample(\n",
       "      (conv): Conv1d(32, 32, kernel_size=(6,), stride=(2,), padding=(2,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Downsample(\n",
       "      (conv): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Downsample(\n",
       "      (conv): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (up_stack): ModuleList(\n",
       "    (0): Upsample(\n",
       "      (conv_transpose): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (1): Upsample(\n",
       "      (conv_transpose): ConvTranspose1d(128, 32, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (2): Upsample(\n",
       "      (conv_transpose): ConvTranspose1d(64, 32, kernel_size=(6,), stride=(2,), padding=(2,))\n",
       "      (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (3): Upsample(\n",
       "      (conv_transpose): ConvTranspose1d(64, 16, kernel_size=(6,), stride=(2,), padding=(2,))\n",
       "      (batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (4): Upsample(\n",
       "      (conv_transpose): ConvTranspose1d(32, 16, kernel_size=(9,), stride=(2,), padding=(4,), output_padding=(1,))\n",
       "      (batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (last): Conv1DTranspose(\n",
       "    (conv_transpose): ConvTranspose1d(32, 1, kernel_size=(9,), stride=(2,), padding=(4,), output_padding=(1,))\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (inputs): Identity()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb028e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "ecg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
